from fastapi import HTTPException
from typing import List, Dict
import logging
import json
import re

from langchain.schema import BaseMessage

from langchain_ollama import ChatOllama
from langchain.prompts import ChatPromptTemplate, PromptTemplate
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain.output_parsers import PydanticOutputParser
from typing import List, Dict, Any

from ..config.config import Config
from ..model.eval_metrics import EvalMetrics
from ..model.persona_spec import PersonaSpec
from ..constant.prompt_constants import DEFAULT_AGENT_INSTRUCTIONS, DEFAULT_INITIAL_GREETING

logger = logging.getLogger("testing-service")
logging.basicConfig(level=logging.INFO)

class TestingService:
    def __init__(self):
        self.config = Config()

        self.llm = ChatOllama(
            model=self.config.MODEL_NAME,  
            base_url="http://localhost:11434/",
            temperature=0.3,
        )

        self.parser = PydanticOutputParser(pydantic_object=EvalMetrics)
        self.eval_prompt = PromptTemplate(
            template="""
        You are an evaluator. Analyze the following transcript and return structured evaluation.

        Give the response in a proper json format only without any additional text.
        Ignore the properties, required and description fields in the schema and give the rest as json.

        Transcript:
        {transcript}

        {format_instructions}
        """,
            input_variables=["transcript"],
            partial_variables={"format_instructions": self.parser.get_format_instructions()},
        )
        self.eval_chain = self.eval_prompt | self.llm


        self.rewrite_prompt = PromptTemplate.from_template("""
        Rewrite the following base agent prompt:

        {base_prompt}

        Incorporating these improvements:
        {edits}

        Return a coherent, concise, professional, empathetic, and legally compliant prompt.
        Provide the revised prompt only, without any additional commentary or explanation on the changes made.
        Keep all the original IMPORTANT instructions unless explicitly told to remove them.
        """)
        self.rewrite_chain = self.rewrite_prompt | self.llm

        self.combine_revisions_prompt = PromptTemplate.from_template("""
        Combine the following changes made to the bas prompt into a single revised prompt:
        Base Prompt:
        {base_prompt}
        Changes:
        {edits}
        Return the revised prompt only, without any additional commentary or explanation on the changes made.
        Keep all the original IMPORTANT instructions unless explicitly told to remove them.                                                         
        """)
        self.combine_revisions_chain = self.combine_revisions_prompt | self.llm

        self.persona_generator_prompt = PromptTemplate.from_template(
        """
        You are a persona generator for credit-card-default call-center training.

        Input: below array of strings of persona type names.
        {persona_type_names}

        Output: array of strings of the same length as above list. For each type, create ONE string that begins:
        “You are [Full Name], a [age]-year-old [occupation] …”

        Each string must include:
        • Identity (name, age, occupation, location, family)  
        • Financial crisis (default reason, timeline, debt amount, default duration)  
        • Personality (3-4 traits)  
        • Current status (employment, income, living situation, other debts, emotional state)  
        • Call objectives (e.g., payment plan, dispute)  
        • Communication style (tone, 2-3 typical phrases, triggers, financial-literacy level)

        Requirements:
        • Realistic, diverse backstories and debt details  
        • Exactly one persona per input type  
        • Return ONLY the string array—no extra text, comments, or formatting, or notes
        - Need only the list of persona descriptions generated by you in the final response you give, as a list of strings.

        Required format of the inal output: 
        ["persona description 1", "persona description 2", etc.]
        """)
        self.persona_prompt = self.persona_generator_prompt | self.llm


    def build_agent_chain(self, base_prompt: str):
        agent_prompt = ChatPromptTemplate.from_messages([
            ("system", base_prompt),
            ("human", "{history}\n\nHuman: {input}\n Just give to-the-point text and nothing else \n\nAssistant: ")
        ])
        memory = ConversationBufferMemory(
            return_messages=True,
            memory_key="history"
        )
        return ConversationChain(
            llm=self.llm,
            prompt=agent_prompt,
            memory=memory,
            input_key="input" 
        )

    def build_persona_chain(self, persona_prompt: str):
        persona_template = ChatPromptTemplate.from_messages([
            ("system", persona_prompt),
            ("human", "{history}\n\nHuman: {input}\n Just give to-the-point text and nothing else \n\nAssistant:")
        ])
        memory = ConversationBufferMemory(
            return_messages=True,
            memory_key="history"
        )
        return ConversationChain(
            llm=self.llm,
            prompt=persona_template,
            memory=memory,
            input_key="input" 
        )

    async def run_simulation(self, base_agent_prompt: str, persona_prompt: str, max_turns: int):
        transcript: List[Dict[str, str]] = []

        agent_chain = self.build_agent_chain(base_agent_prompt or DEFAULT_AGENT_INSTRUCTIONS)
        persona_chain = self.build_persona_chain(persona_prompt)

        # Agent opens the conversation
        agent_msg = await agent_chain.apredict(input=DEFAULT_INITIAL_GREETING)
        transcript.append({"role": "agent", "text": agent_msg})

        for _ in range(max_turns):
            persona_msg = await persona_chain.apredict(input=agent_msg)
            transcript.append({"role": "persona", "text": persona_msg})

            if any(kw in persona_msg.lower() for kw in ["i'll pay", "i will pay", "i agree", "schedule payment", "pay today", "make a payment", "pay now", "i can pay"]):
                break

            agent_msg = await agent_chain.apredict(input=persona_msg)
            transcript.append({"role": "agent", "text": agent_msg})

        return transcript

    async def evaluate_conversation(self, transcript: List[Dict[str, str]]) -> Dict[str, Any]:
        convo_text = "\n".join([f"{m['role'].upper()}: {m['text']}" for m in transcript])
        raw = await self.eval_chain.ainvoke(input={"transcript": convo_text})
        try:
            metrics = self.extract_recommendations(raw)
        except Exception as e:
            raise HTTPException(status_code=500, detail=f"Eval parse failed: {e}. Raw: {raw}")
        return metrics

    async def rewrite_prompt_text(self, base_prompt: str, edits: List[str]) -> str:
        if not edits:
            return base_prompt
        edits_text = "\n".join([f"- {e}" for e in edits])
        revised_prompt = await self.rewrite_chain.ainvoke(input={"base_prompt": base_prompt, "edits": edits_text})
        return str(revised_prompt.content).strip()
    
    async def combine_prompt_revisions(self, base_prompt: str, edits: List[str]) -> str:
        if not edits:
            return base_prompt
        edits_text = "\n".join([f"- {e}" for e in edits])
        revised_prompt = await self.combine_revisions_chain.ainvoke(input={"base_prompt": base_prompt, "edits": edits_text})
        return str(revised_prompt.content).strip()
    
    def extract_recommendations(self, raw: BaseMessage) -> Dict[str, Any]:
        text = raw.content
        try:
            data = json.loads(text)
        except json.JSONDecodeError:
            print("Invalid JSON:", text)
            data = {}
        return data
    
    async def generate_personas(self, persona_names: List[str]) -> List[str]:
        personas = []
        response = await self.persona_prompt.ainvoke(input={"persona_type_names": json.dumps(persona_names)})
        content = response.content
        
        array_pattern = r'\[(?:\s*"[^"]*"\s*,?\s*)*\]'
        match = re.search(array_pattern, content, re.DOTALL)
        
        if match:
            json_array_str = match.group(0)
            try:
                personas = json.loads(json_array_str)
                personas = [str(item) for item in personas if isinstance(item, str)]
            except json.JSONDecodeError:
                print("Invalid JSON after regex extraction:", json_array_str)
        else:
            print("No JSON array found in the response content.")
            print("Response content:", content)
        
        return personas
            

    
